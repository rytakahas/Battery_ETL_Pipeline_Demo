{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from urllib.parse import urlparse, unquote\n",
    "from confluent_kafka import Producer\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration for MinIO\n",
    "MINIO_ENDPOINT = \"m3g2.ldn.idrivee2-66.com\"\n",
    "MINIO_ACCESS_KEY = \"qy1bbnyZNrTbkzd63k7d\"\n",
    "MINIO_SECRET_KEY = \"D7yiFWqeYUYGykqrEvtVJa6il4bWKVtfwnN0Wop3\"\n",
    "MINIO_BUCKET = \"battery-data\"\n",
    "\n",
    "# Kafka Producer config (Redpanda)\n",
    "producer = Producer({'bootstrap.servers': 'localhost:9092'})\n",
    "\n",
    "# Set up MinIO client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=f\"https://{MINIO_ENDPOINT}\",\n",
    "    aws_access_key_id=MINIO_ACCESS_KEY,\n",
    "    aws_secret_access_key=MINIO_SECRET_KEY\n",
    ")\n",
    "\n",
    "# Ensure bucket exists or create it\n",
    "try:\n",
    "    s3.head_bucket(Bucket=MINIO_BUCKET)\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == '404':\n",
    "        s3.create_bucket(Bucket=MINIO_BUCKET)\n",
    "        print(f\"Created bucket: {MINIO_BUCKET}\")\n",
    "    else:\n",
    "        print(\"Bucket access failed:\", e)\n",
    "        raise\n",
    "\n",
    "# Dataset URLs\n",
    "dataset_urls = [\n",
    "    \"https://web.calce.umd.edu/batteries/data/SP1_Initial%20capacity_10_16_2015.zip\",\n",
    "    \"https://web.calce.umd.edu/batteries/data/SP2_25C_FUDS.zip\"\n",
    "]\n",
    "\n",
    "def acked(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Delivery failed:\", err)\n",
    "    else:\n",
    "        print(\"Delivered:\", msg.value().decode())\n",
    "\n",
    "# Stream and upload pipeline\n",
    "for zip_url in dataset_urls:\n",
    "    parsed_url = urlparse(zip_url)\n",
    "    zip_filename = os.path.basename(unquote(parsed_url.path))\n",
    "    zip_path = os.path.join(\"battery_data\", zip_filename)\n",
    "    extract_dir = os.path.join(\"battery_data\", os.path.splitext(zip_filename)[0])\n",
    "\n",
    "    os.makedirs(\"battery_data\", exist_ok=True)\n",
    "\n",
    "    print(f\"\\n Downloading: {zip_filename}\")\n",
    "    if not os.path.exists(zip_path):\n",
    "        r = requests.get(zip_url, verify=False)\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"️Downloaded to: {zip_path}\")\n",
    "    else:\n",
    "        print(\"ZIP already exists. Skipping download.\")\n",
    "\n",
    "    print(f\"Extracting to: {extract_dir}\")\n",
    "    if not os.path.exists(extract_dir):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "    else:\n",
    "        print(\"Directory already exists. Skipping extraction.\")\n",
    "\n",
    "    files = os.listdir(extract_dir)\n",
    "    target_file = next((os.path.join(extract_dir, f) for f in files if f.lower().endswith((\".xlsx\", \".xls\"))), None)\n",
    "    if not target_file:\n",
    "        raise FileNotFoundError(f\"No Excel file found in {extract_dir}.\")\n",
    "\n",
    "    print(f\"Reading Excel: {target_file}\")\n",
    "    df = pd.read_excel(target_file, engine=\"openpyxl\")\n",
    "    df = df.dropna(how='all').reset_index(drop=True)\n",
    "    df[\"id\"] = df.index\n",
    "    df[\"source_file\"] = zip_filename\n",
    "    df[\"streamed_at\"] = pd.Timestamp.now()\n",
    "\n",
    "    # Save as CSV\n",
    "    temp_csv_path = os.path.join(\"battery_data\", f\"{os.path.splitext(zip_filename)[0]}.csv\")\n",
    "    df.to_csv(temp_csv_path, index=False)\n",
    "\n",
    "    # Upload to MinIO\n",
    "    try:\n",
    "        s3.upload_file(temp_csv_path, MINIO_BUCKET, os.path.basename(temp_csv_path))\n",
    "        print(f\"Uploaded to MinIO: {os.path.basename(temp_csv_path)}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"Failed to upload to MinIO: credentials error\")\n",
    "    except ClientError as e:\n",
    "        print(\"MinIO upload error:\", e)\n",
    "\n",
    "    # Kafka Streaming\n",
    "    print(\"Streaming rows to Redpanda...\")\n",
    "    for _, row in df.iterrows():\n",
    "        record = {\n",
    "            k: str(v) if isinstance(v, (pd.Timestamp, datetime)) else v\n",
    "            for k, v in row.to_dict().items()\n",
    "        }\n",
    "        try:\n",
    "            producer.produce(\n",
    "                topic=\"battery_topic\",\n",
    "                key=str(record[\"id\"]),\n",
    "                value=json.dumps(record),\n",
    "                callback=acked\n",
    "            )\n",
    "            producer.poll(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Kafka produce failed: {e}\")\n",
    "        time.sleep(0.005)\n",
    "\n",
    "producer.flush()\n",
    "print(\"All data streamed to Redpanda and uploaded to MinIO.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45921e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import libraries and re-run logic after code execution environment reset\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "\n",
    "# Configuration for MinIO\n",
    "MINIO_ENDPOINT = \"https://m3g2.ldn.idrivee2-66.com\"\n",
    "MINIO_ACCESS_KEY = \"qy1bbnyZNrTbkzd63k7d\"\n",
    "MINIO_SECRET_KEY = \"D7yiFWqeYUYGykqrEvtVJa6il4bWKVtfwnN0Wop3\"\n",
    "MINIO_BUCKET = \"battery-data\"\n",
    "\n",
    "# Set up MinIO client\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=MINIO_ACCESS_KEY,\n",
    "    aws_secret_access_key=MINIO_SECRET_KEY\n",
    ")\n",
    "\n",
    "# List CSV files from MinIO\n",
    "csv_files = [obj[\"Key\"] for obj in s3.list_objects_v2(Bucket=MINIO_BUCKET)[\"Contents\"] if obj[\"Key\"].endswith(\".csv\")]\n",
    "\n",
    "# Load and clean all CSVs\n",
    "all_dfs = []\n",
    "for key in csv_files:\n",
    "    response = s3.get_object(Bucket=MINIO_BUCKET, Key=key)\n",
    "    df = pd.read_csv(response[\"Body\"])\n",
    "    df.columns = [col.strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "    df = df.dropna(how=\"all\")\n",
    "    for col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "        except Exception:\n",
    "            continue\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df_cleaned = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Connect to MotherDuck and store the cleaned table\n",
    "conn = duckdb.connect(\"md:battery_db?motherduck_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6InJ5b2ppLnRha2FoYXNoaUBnbWFpbC5jb20iLCJzZXNzaW9uIjoicnlvamkudGFrYWhhc2hpLmdtYWlsLmNvbSIsInBhdCI6Im5FM3NZLXdENEhWcWR0aUotcmZUazlyZVlkT3VEY21GWWJXaC1QbGVPNWsiLCJ1c2VySWQiOiIwNGZiODAyZS01MjJhLTQ1MDMtOTYyMC1mYmNiNzJjNmJiYjkiLCJpc3MiOiJtZF9wYXQiLCJyZWFkT25seSI6ZmFsc2UsInRva2VuVHlwZSI6InJlYWRfd3JpdGUiLCJpYXQiOjE3NDczMTk4NzV9.dDFrp-nsxROrdV1_QnBNlrAx3E8de0ZUOMfaGLQOiZ4\")\n",
    "conn.execute(\"DROP TABLE IF EXISTS battery_cleaned\")\n",
    "conn.register(\"battery_cleaned_view\", df_cleaned)\n",
    "conn.execute(\"CREATE TABLE battery_cleaned AS SELECT * FROM battery_cleaned_view\")\n",
    "\n",
    "# Preview cleaned data\n",
    "df_preview = conn.execute(\"SELECT * FROM battery_cleaned LIMIT 50\").fetchdf()\n",
    "\n",
    "import ace_tools_open as tools; tools.display_dataframe_to_user(name=\"Preview Cleaned Battery Data from MinIO\", dataframe=df_preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413a343",
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_cols = df_preview.columns\n",
    "print(phys_cols)\n",
    "\n",
    "df_cleaned = df_preview.dropna(subset=phys_cols)\n",
    "print(df_cleaned.isna().sum())\n",
    "\n",
    "# Drop constant columns (e.g. all 0s or same value)\n",
    "n_unique = df_cleaned.nunique()\n",
    "constant_cols = n_unique[n_unique <= 1].index.tolist()\n",
    "\n",
    "print(\"Dropping constant columns:\", constant_cols)\n",
    "df_cleaned = df_cleaned.drop(columns=constant_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cleaned.info())\n",
    "print(df_cleaned.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cleaned shape:\", df_cleaned.shape)\n",
    "print(\"Remaining columns:\", df_cleaned.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa24b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cleaned.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Connect to MotherDuck\n",
    "conn = duckdb.connect(f\"md:battery_db?motherduck_token={MOTHERDUCK_TOKEN}\")\n",
    "\n",
    "# Drop existing object regardless of type\n",
    "try:\n",
    "    conn.execute(\"DROP VIEW IF EXISTS battery_ts\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    conn.execute(\"DROP TABLE IF EXISTS battery_ts\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Recreate as a physical table from the cleaned version\n",
    "conn.execute(\"CREATE TABLE battery_ts AS SELECT * FROM battery_ts_cleaned\")\n",
    "\n",
    "print(\"✅ Final warehouse table 'battery_ts' created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
